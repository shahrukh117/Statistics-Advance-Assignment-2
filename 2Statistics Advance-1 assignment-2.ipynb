{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ac0437-2825-4163-93b6-038511308572",
   "metadata": {},
   "source": [
    "### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3736b-ad09-45f2-b2f6-c356b19021a8",
   "metadata": {},
   "source": [
    "### Probability Mass Function (PMF) and Probability Density Function (PDF)\n",
    "\n",
    "**Probability Mass Function (PMF):**\n",
    "- *Definition:* The PMF gives the probability that a discrete random variable takes on a specific value.\n",
    "- *Denoted as:* P(X = x), where X is the random variable and x is a specific value it can take.\n",
    "- *Properties:* The PMF must satisfy two conditions: 1) The probability for any specific value is between 0 and 1, and 2) The sum of probabilities over all possible values is equal to 1.\n",
    "- *Example:* Consider a fair six-sided die. The PMF for the value X (the outcome of a single roll) is P(X = 1) = 1/6, P(X = 2) = 1/6, and so on. The sum of all these probabilities is 1.\n",
    "\n",
    "**Probability Density Function (PDF):**\n",
    "- *Definition:* The PDF gives the probability density of a continuous random variable at a particular point.\n",
    "- *Denoted as:* f(x), where x is a specific value of the continuous random variable.\n",
    "- *Properties:* Unlike the PMF, the probability for a specific value in a continuous distribution is technically zero. Instead, the area under the PDF curve within a range corresponds to the probability of the variable falling within that range.\n",
    "- *Example:* Consider a standard normal distribution with mean 0 and standard deviation 1. The PDF for the random variable Z is denoted as f(z) = (1/√(2π)) * e^(-z^2/2). In this case, the probability of Z falling within a specific range is calculated by integrating the PDF over that range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b09af-c7de-4652-815a-7dc8c1db43dd",
   "metadata": {},
   "source": [
    "### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9fa6e3-3d9b-4b7a-81d4-3c7db10ce91a",
   "metadata": {},
   "source": [
    "\n",
    "The cumulative distribution function (CDF) is a fundamental concept in probability and statistics. It describes the probability that a random variable will take on a value less than or equal to a certain point. In simpler terms, it tells you what the likelihood is that a particular event will happen.\n",
    "\n",
    "Here's an example to illustrate:\n",
    "\n",
    "Imagine you roll a fair six-sided die. The random variable here is the number rolled. The CDF for this scenario would look like this:\n",
    "\n",
    "P(X ≤ 1) = 1/6 (probability of rolling 1 or less)\n",
    "\n",
    "P(X ≤ 2) = 2/6 (probability of rolling 1 or 2 or less)\n",
    "\n",
    "P(X ≤ 3) = 3/6 (probability of rolling 1, 2, or 3 or less)\n",
    "\n",
    "P(X ≤ 4) = 4/6 (probability of rolling 1, 2, 3, or 4 or less)\n",
    "\n",
    "P(X ≤ 5) = 5/6 (probability of rolling 1, 2, 3, 4, or 5 or less)\n",
    "\n",
    "P(X ≤ 6) = 6/6 (probability of rolling 1, 2, 3, 4, 5, or 6 or less, which is always true)\n",
    "\n",
    "As you can see, the CDF is a non-decreasing function that starts at 0 and ends at 1. This makes sense because the probability of a random variable being less than or equal to some value can never be negative and must eventually reach 1 as we consider all possible values.\n",
    "\n",
    "So, why is the CDF useful? Here are some reasons:\n",
    "\n",
    "Calculating probabilities: You can use the CDF to calculate the probability of a specific event happening. For example, in the dice example, you could use the CDF to find the probability of rolling a 4 or less (which is 4/6).\n",
    "Comparing distributions: CDFs can be visually compared to see how different distributions differ. For example, you could compare the CDF of the roll of a fair die to the CDF of a loaded die to see how the probabilities of different outcomes are affected.\n",
    "Generating random numbers: CDFs can be used to generate random numbers according to a specific distribution. This is useful in many applications, such as simulations and Monte Carlo methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12e786-2756-41e3-b67b-225e0731ce25",
   "metadata": {},
   "source": [
    "### Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb8f05-673d-4bf2-a2e8-1b4fbed4716c",
   "metadata": {},
   "source": [
    "### Normal Distribution in Various Situations\n",
    "\n",
    "The normal distribution, also known as the Gaussian distribution or bell curve, is widely used in various fields to model the distribution of random variables. Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "1. **Height of a Population:** The distribution of heights in a population often follows a normal distribution, with most people clustered around the average height.\n",
    "\n",
    "2. **IQ Scores:** Intelligence Quotient (IQ) scores are often modeled using a normal distribution, where the mean represents the average intelligence level and the standard deviation captures the spread of scores.\n",
    "\n",
    "3. **Errors in Measurements:** In many scientific experiments, measurement errors are assumed to be normally distributed. This assumption is fundamental in statistical hypothesis testing and parameter estimation.\n",
    "\n",
    "4. **Financial Data:** Stock prices and returns, as well as other financial metrics, are often assumed to be normally distributed, especially when considering large numbers of transactions.\n",
    "\n",
    "5. **Blood Pressure:** The distribution of blood pressure in a population is often modeled using a normal distribution, with the mean representing the average blood pressure.\n",
    "\n",
    "### Parameters of the Normal Distribution\n",
    "\n",
    "Parameters of the normal distribution are the mean $(\\mu)$ and the standard deviation $(\\sigma)$. These parameters affect the shape of the distribution in the following ways:\n",
    "\n",
    "1. **Mean $(\\mu)$:** The mean is the central value around which the distribution is symmetric. It represents the peak or center of the bell curve. Shifting the mean to the left or right will move the entire distribution along the horizontal axis.\n",
    "\n",
    "2. **Standard Deviation $(\\sigma)$:** The standard deviation measures the spread or dispersion of the distribution. A larger standard deviation results in a wider and flatter curve, indicating greater variability in the data. Conversely, a smaller standard deviation results in a narrower and taller curve, indicating less variability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06d098-ec4b-4056-ab57-24f729128b5b",
   "metadata": {},
   "source": [
    "### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c12424-baef-485d-82dd-2ad4f096f218",
   "metadata": {},
   "source": [
    "### Importance of Normal Distribution\n",
    "\n",
    "The normal distribution holds significant importance in statistics and probability theory for various reasons:\n",
    "\n",
    "1. **Central Limit Theorem (CLT):** The normal distribution is a fundamental part of the Central Limit Theorem, stating that the distribution of the sum or average of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the original distribution. This theorem is crucial for statistical inference and hypothesis testing.\n",
    "\n",
    "2. **Statistical Inference:** Many statistical methods, such as hypothesis testing and confidence interval estimation, rely on assumptions of normality. The normal distribution provides a convenient and analytically tractable framework for conducting statistical analyses.\n",
    "\n",
    "3. **Parameter Estimation:** In parametric statistics, the normal distribution serves as a foundation for estimating population parameters, making it easier to derive maximum likelihood estimates and other statistical measures.\n",
    "\n",
    "4. **Predictive Modeling:** The normal distribution is frequently used to model the distribution of various phenomena in the natural world, making it a valuable tool for making predictions and understanding the behavior of random variables.\n",
    "\n",
    "5. **Standardization:** The normal distribution is standardized with a well-defined mean and standard deviation. This standardization facilitates comparisons and analyses across different datasets, providing a common scale of measurement.\n",
    "\n",
    "#### Real-Life Examples of Normal Distribution\n",
    "\n",
    "1. **Height of Adults:** The heights of adult individuals in a population often approximate a normal distribution, with most people clustered around the average height.\n",
    "\n",
    "2. **IQ Scores:** Intelligence Quotient (IQ) scores are designed to follow a normal distribution with a mean of 100 and a standard deviation of 15, allowing for comparisons relative to the population.\n",
    "\n",
    "3. **Grades in a Classroom:** The distribution of grades in a well-designed exam for a large classroom tends to follow a normal distribution, with most students near the average grade.\n",
    "\n",
    "4. **Blood Pressure:** The distribution of blood pressure in a population often exhibits a normal distribution, with the mean representing the typical blood pressure level.\n",
    "\n",
    "5. **Body Temperature:** Human body temperature is approximately normally distributed, with the mean around 98.6°F (37°C).\n",
    "\n",
    "6. **Reaction Times:** The time it takes for individuals to react to a stimulus, such as in psychological experiments, often follows a normal distribution.\n",
    "\n",
    "7. **Financial Returns:** Daily or monthly returns on financial instruments like stocks, when observed over a long period, often exhibit a distribution that approximates normality.\n",
    "\n",
    "8. **Errors in Measurements:** Measurement errors in scientific experiments are often assumed to be normally distributed, a crucial assumption in statistical analysis.\n",
    "\n",
    "9. **Population Birth Weights:** The distribution of birth weights in a population is often modeled using a normal distribution.\n",
    "\n",
    "10. **Residuals in Regression Analysis:** In regression analysis, the distribution of residuals (the differences between observed and predicted values) is often assumed to be normal for valid statistical inferences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eeb035-1a00-4c21-9eee-1f84a7738fe1",
   "metadata": {},
   "source": [
    "### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dccf9cb-519f-4541-b4a2-4d7020c6e4c8",
   "metadata": {},
   "source": [
    "### Bernoulli Distribution\n",
    "\n",
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with only two possible outcomes: success and failure. It is named after Jacob Bernoulli, a Swiss mathematician. The distribution is characterized by a single parameter \\( p \\), representing the probability of success.\n",
    "\n",
    "The probability mass function (PMF) of a Bernoulli-distributed random variable \\( X \\) is given by:\n",
    "\n",
    "\\[ P(X = k) = \\begin{cases} \n",
    "p & \\text{if } k = 1 \\\\\n",
    "1 - p & \\text{if } k = 0 \n",
    "\\end{cases} \\]\n",
    "\n",
    "Here, \\( k \\) is the outcome (1 for success, 0 for failure), and \\( p \\) is the probability of success.\n",
    "\n",
    "#### Example of Bernoulli Distribution\n",
    "\n",
    "Consider a single flip of a biased coin. Let \\( X \\) be a random variable representing the outcome, where \\( X = 1 \\) if the coin lands on heads (success) and \\( X = 0 \\) if it lands on tails (failure). If the probability of getting heads is \\( p = 0.6 \\), then the Bernoulli distribution can be used to model the probability of success or failure in a single coin flip.\n",
    "\n",
    "### Difference between Bernoulli and Binomial Distribution\n",
    "\n",
    "1. **Number of Trials:**\n",
    "   - **Bernoulli Distribution:** Models a single trial or experiment with two possible outcomes (success or failure).\n",
    "   - **Binomial Distribution:** Models the number of successes in a fixed number of independent Bernoulli trials.\n",
    "\n",
    "2. **Random Variables:**\n",
    "   - **Bernoulli Distribution:** Has only one random variable, representing the outcome of a single trial.\n",
    "   - **Binomial Distribution:** Involves the sum of multiple independent Bernoulli-distributed random variables, representing the total number of successes in a fixed number of trials.\n",
    "\n",
    "3. **Probability Mass Function (PMF):**\n",
    "   - **Bernoulli Distribution:** $( P(X = k) = p^k \\cdot (1 - p)^{1-k}$ for $( k )$ in ${0, 1\\}$.\n",
    "   - **Binomial Distribution:** The PMF gives the probability of obtaining $ k $ successes in $ n $ trials and is expressed as $ P(X = k) = \\binom{n}{k} \\cdot p^k \\cdot (1 - p)^{n-k}$.\n",
    "\n",
    "4. **Parameters:**\n",
    "   - **Bernoulli Distribution:** Characterized by a single parameter $ p $, representing the probability of success.\n",
    "   - **Binomial Distribution:** Characterized by two parameters, $ n $ (number of trials) and $ p $ (probability of success in each trial).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955efe4-f3d1-4b42-8998-f51cd3c0f4c4",
   "metadata": {},
   "source": [
    "### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5560b96-12ce-4d6b-9fbd-acb78bcce831",
   "metadata": {},
   "source": [
    "First, calculate the z-score for 60:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "X is the value in question (60 in this case),\n",
    "\n",
    "μ is the mean of the dataset (50),\n",
    "\n",
    "σ is the standard deviation of the dataset (10).\n",
    "\n",
    "z = (60 - 50) / 10\n",
    "z = 10 / 10\n",
    "z = 1\n",
    "\n",
    "\n",
    "Next, we look up the z-score of 1 in the standard normal distribution table to find the corresponding probability. From the table, we find that the probability of a z-score of 1 or greater is approximately 0.8413.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from this dataset will be greater than 60 is 0.8413, or 84.13%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a12f1-83f1-4170-b3e4-5db09fa3592b",
   "metadata": {},
   "source": [
    "### Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6902c2-c4d2-4bd9-a9e1-f0b4c39f6bb7",
   "metadata": {},
   "source": [
    "Uniform distribution is a probability distribution in which all outcomes are equally likely to occur. In a uniform distribution, the probability of each individual outcome is constant and all outcomes have the same likelihood of happening. This results in a horizontal, flat line when the probability density function is graphed.\n",
    "\n",
    "An example of a uniform distribution is rolling a fair six-sided die. When you roll a fair six-sided die, each number (1, 2, 3, 4, 5, 6) has an equal probability of 1/6 (approximately 0.167) of occurring. This means that the distribution is uniform because each outcome (each number on the die) has the same probability of being rolled.\n",
    "\n",
    "Another example of a uniform distribution is spinning a spinner with 8 equal sections, each labeled with a different color. Each color on the spinner has an equal probability of occurring, making it a uniform distribution.\n",
    "\n",
    "In general, uniform distributions are used when dealing with situations where all outcomes are equally likely to occur, and there is no skewness or bias towards any particular outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a256e-16d5-4448-a4d5-ea9221be8f5b",
   "metadata": {},
   "source": [
    "### Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe8bba-8124-4ad6-989f-30df6de32de8",
   "metadata": {},
   "source": [
    "A z-score, also known as a standard score, is a statistical measurement that tells you how many standard deviations a specific point is away from the mean in a given dataset. It essentially standardizes your data by expressing its distance from the average in terms of the spread (standard deviation) of the data.\n",
    "\n",
    "#### Importance of Z-scores:\n",
    "\n",
    "**Comparing data across different datasets:** Z-scores allow you to compare data points from different datasets, even if they have different units or scales. This is because they represent the relative position of a point within its own distribution, unabhängig of the actual numerical values.\n",
    "\n",
    "**Identifying outliers:** Z-scores help in identifying outliers, which are data points that deviate significantly from the rest of the data. Values with high absolute z-scores (typically above 3 or below -3) are considered potential outliers and warrant further investigation.\n",
    "\n",
    "**Hypothesis testing:** Z-scores play a crucial role in various statistical tests, such as the z-test, which helps assess the probability of obtaining a specific observation if the null hypothesis (no difference between groups) is true.\n",
    "\n",
    "**Understanding data distribution:** Analyzing the distribution of z-scores in a dataset can reveal its underlying shape (e.g., normal, skewed). This information is valuable for choosing appropriate statistical methods for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ecf95d-df7d-4c83-a568-aa5084d68452",
   "metadata": {},
   "source": [
    "### Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf65e45-67bd-4f53-8c33-9e04afb7a233",
   "metadata": {},
   "source": [
    "Central limit theorem states that, if you have a population mean(mu) and standard deviation (sigma) and take large random sample from the population with replacement.\n",
    "\n",
    "Then the distribution of the sample mean will be approximately normally distributed regardless of whether the population is normal or skewed.\n",
    "provided that the sample size is sufficiently large (n>30).\n",
    "\n",
    "### Significance of the Central Limit Theorem:\n",
    "\n",
    "**Wide applicability:** The CLT applies to a vast range of situations, making it one of the most important theorems in statistics. It allows us to use tools and theories developed for the normal distribution (e.g., confidence intervals, hypothesis tests) on diverse data, even if we don't know the exact population distribution.\n",
    "\n",
    "**Justification for using normal distribution methods:** Many statistical methods rely on the normal distribution, but data in real-world scenarios rarely follows a perfect normal distribution. The CLT assures us that for large enough samples, the distribution of the sample mean behaves like a normal distribution even if the individual data points don't, allowing us to apply those methods confidently.\n",
    "\n",
    "**Confidence intervals and hypothesis testing:** The CLT plays a crucial role in constructing confidence intervals for population parameters (e.g., mean) and conducting hypothesis tests about those parameters. It allows us to estimate the range within which the true population parameter likely lies and assess the evidence against the null hypothesis based on sample data, even with non-normal populations.\n",
    "\n",
    "**Underlying many statistical techniques:** The CLT underpins various statistical techniques, including linear regression, t-tests, chi-square tests, and analysis of variance (ANOVA). Understanding the CLT is essential for interpreting and applying these techniques correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9907756-6530-4969-9058-427db0c1aa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d556d0d1-ef39-4758-9ba5-0de38654d788",
   "metadata": {},
   "source": [
    "# Assumptions of the Central Limit Theorem (CLT)\n",
    "\n",
    "1. **Independence of Observations:**\n",
    "   - The samples or observations must be independent. This means that the occurrence or value of one observation should not influence or be influenced by the occurrence or value of another observation.\n",
    "\n",
    "2. **Identically Distributed:**\n",
    "   - The random variables being sampled should be identically distributed. This assumption ensures that each observation comes from the same population with the same underlying probability distribution.\n",
    "\n",
    "3. **Finite Mean and Variance:**\n",
    "   - The population from which the samples are drawn should have a finite mean (\\( \\mu \\)) and a finite variance (\\( \\sigma^2 \\)). This ensures that the first and second moments of the distribution exist.\n",
    "\n",
    "4. **Random Sampling:**\n",
    "   - The samples must be drawn randomly from the population. This means that each member of the population has an equal chance of being selected, and the sampling process is unbiased.\n",
    "\n",
    "5. **Sample Size is Sufficiently Large:**\n",
    "   - The Central Limit Theorem is more reliable as the sample size (\\( n \\)) increases. While there is no strict rule for what constitutes a \"sufficiently large\" sample size, a common guideline is that ( n >= 30 ) is often considered adequate for the CLT to apply. In some cases, larger sample sizes may be required, especially if the population distribution is highly skewed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159fe09-642f-4a4f-a692-01e6daeafa10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
